{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import datetime\n",
    "from geopy.geocoders import Nominatim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_file_path = \"assets\\house_price.csv\"\n",
    "used_columns_list = ['Land_Sale_Price', 'Total_sale_Price', 'Deed_Date', 'Assessed_Building_Value', 'Story_Height', 'HEATED_AREA',\n",
    "       'UTILITIES', 'Remodeled_Year', 'BATH', 'BATH_FIXTURES', 'TYPE_AND_USE', 'PHYSICAL_ZIP_CODE', 'PHYSICAL_CITY', 'Street_Number', \n",
    "       'Street_Name', 'Street_Type', 'Planning_Jurisdiction']\n",
    "wake_cities = ['APEX', 'CARY', 'FUQUAY VARINA', 'GARNER', 'HOLLY SPRINGS', 'KNIGHTDALE', 'MORRISVILLE', 'RALEIGH', 'ROLESVILLE', 'WAKE FOREST', 'WENDELL', 'ZEBULON']\n",
    "\n",
    "column_dropna = ['UTILITIES', 'BATH', 'Story_Height']\n",
    "\n",
    "update_location = {'5500 BATOUL LN, raleigh': '27606',\n",
    "                   '1436 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1432 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1428 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1424 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1420 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1416 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1412 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1413 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1429 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1433 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1517 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1519 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1521 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1523 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1520 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1518 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '1516 INDIGO CREEK DR, zebulon': '27597',\n",
    "                   '529 BASIN HILL DR, wake forest': '27587',\n",
    "                   '505 BASIN HILL DR, wake forest': '27587',\n",
    "                   '501 BASIN HILL DR, wake forest': '27587'}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv(file_path, print_columns=False):\n",
    "    \"\"\"Read csv files and return a dataframe\n",
    "    \n",
    "    Args:\n",
    "        file_path (str): path of the csv file\n",
    "        print_columns (bool): print columns of the dataframe (default: False)\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path)\n",
    "    if print_columns:\n",
    "        print(df.columns)\n",
    "    print(df.shape)\n",
    "    print(\"The data is loaded successfully!\")\n",
    "    return df\n",
    "    \n",
    "def used_columns_df(df, columns):\n",
    "    \"\"\"Keep only the used columns\n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): dataframe\n",
    "        columns (list): list of columns\n",
    "    \"\"\"\n",
    "    new_df = df[columns].copy()\n",
    "    return new_df\n",
    "\n",
    "def format_price_value(df, column, convert_type, replace=False):\n",
    "    \"\"\"Convert price value to float\n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): dataframe\n",
    "        column (str): column name\n",
    "        convert_type (str): convert type\n",
    "        replace (bool): replace the original column or not (default: False)\n",
    "    \"\"\"\n",
    "    if replace:\n",
    "        df[column] = df[column].str.replace(',', '').astype(convert_type)\n",
    "    df[column] = df[column].astype(convert_type)\n",
    "    print(f\"{column} is converted successfully\")\n",
    "    return df\n",
    "\n",
    "def format_date(df, column, errors='coerce'):\n",
    "    \"\"\"Convert format of date\n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): dataframe\n",
    "        column (str): column name\n",
    "        errors (str): errors (default: 'coerce')\n",
    "    \"\"\"\n",
    "    df[column] = pd.to_datetime(df[column], errors=errors)\n",
    "    print(f\"{column} is converted successfully\")\n",
    "    return df\n",
    "\n",
    "def fill_drop_na(df, column, fill_zero=True):\n",
    "    \"\"\"Fill or drop na values\n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): dataframe\n",
    "        column (str): column name\n",
    "        fill_zero (bool): fill na as zero or not (default: True)\n",
    "    \"\"\"\n",
    "    if column == 'Deed_Date':\n",
    "        df.loc[df[column].isnull(), column] = df['Remodeled_Year']\n",
    "    elif column in column_dropna:\n",
    "        df.dropna(subset=[column], inplace=True)\n",
    "        df.reset_index(drop=True, inplace=True)\n",
    "        print(f\"None value in {column} is dropped successfully\")\n",
    "        print(\"Index of the dataframe is reset successfully\")\n",
    "        return df\n",
    "    else:\n",
    "        if fill_zero:\n",
    "            df[column] = df[column].fillna(0).astype(int)\n",
    "    print(f\"Number of nan values of {column} is {df[column].isnull().sum()}\")\n",
    "    return df\n",
    "\n",
    "def remove_zero(df, column):\n",
    "    \"\"\"Remove zero values\n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): dataframe\n",
    "        column (str): column name\n",
    "    \"\"\"\n",
    "    df = df[df[column] != 0]\n",
    "    print(f\"Number of zero values of {column} is {df[column].eq(0).sum()}\")\n",
    "    return df\n",
    "\n",
    "def convert_categorical_to_numeric_variables(df, variable):\n",
    "    \"\"\"Convert categorical variables to numeric variables\n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): dataframe\n",
    "        variable (str): variable name\n",
    "    \"\"\"\n",
    "    if variable == 'BATH':\n",
    "        df.loc[df['BATH'] == 'A', 'BATH'] = 1\n",
    "        df.loc[df['BATH'] == 'B', 'BATH'] = 1.5\n",
    "        df.loc[df['BATH'] == 'C', 'BATH'] = 2\n",
    "        df.loc[df['BATH'] == 'D', 'BATH'] = 2.5\n",
    "        df.loc[df['BATH'] == 'E', 'BATH'] = 3\n",
    "        df.loc[df['BATH'] == 'F', 'BATH'] = 3.5\n",
    "        df.loc[df['BATH'] == 'G', 'BATH'] = 0\n",
    "        df.loc[df['BATH'] == 'H', 'BATH'] = 0\n",
    "        df.loc[(df['BATH'] == 'I') & (df['BATH_FIXTURES'] <= 3), 'BATH'] = 0\n",
    "        df.loc[(df['BATH'] == 'I') & (df['BATH_FIXTURES'] <= 6), 'BATH'] = 1\n",
    "        df.loc[(df['BATH'] == 'I') & (df['BATH_FIXTURES'] == 7), 'BATH'] = 1.5\n",
    "        df.loc[(df['BATH'] == 'I') & (df['BATH_FIXTURES'] == 8), 'BATH'] = 2\n",
    "        df.loc[(df['BATH'] == 'I') & (df['BATH_FIXTURES'] == 9), 'BATH'] = 2.5\n",
    "        df.loc[(df['BATH'] == 'I') & (df['BATH_FIXTURES'] == 10), 'BATH'] = 3\n",
    "        df.loc[(df['BATH'] == 'I') & (df['BATH_FIXTURES'] == 11), 'BATH'] = 3.5\n",
    "        df.loc[(df['BATH'] == 'I') & (df['BATH_FIXTURES'] > 11), 'BATH'] = 4\n",
    "        \n",
    "        df.loc[(df['BATH'] == 'J') & (df['BATH_FIXTURES'] <= 3), 'BATH'] = 0\n",
    "        df.loc[(df['BATH'] == 'J') & (df['BATH_FIXTURES'] <= 6), 'BATH'] = 1\n",
    "        df.loc[(df['BATH'] == 'J') & (df['BATH_FIXTURES'] == 7), 'BATH'] = 1.5\n",
    "        df.loc[(df['BATH'] == 'J') & (df['BATH_FIXTURES'] == 8), 'BATH'] = 2\n",
    "        df.loc[(df['BATH'] == 'J') & (df['BATH_FIXTURES'] == 9), 'BATH'] = 2.5\n",
    "        df.loc[(df['BATH'] == 'J') & (df['BATH_FIXTURES'] == 10), 'BATH'] = 3\n",
    "        df.loc[(df['BATH'] == 'J') & (df['BATH_FIXTURES'] == 11), 'BATH'] = 3.5\n",
    "        df.loc[(df['BATH'] == 'J') & (df['BATH_FIXTURES'] > 11), 'BATH'] = 4\n",
    "        print(\"Bathroom number is converted successfully\")\n",
    "        return df\n",
    "\n",
    "    elif variable == 'Story_Height':\n",
    "        df.loc[df['Story_Height'] == 'A', 'Story_Height'] = 1\n",
    "        df.loc[df['Story_Height'] == 'B', 'Story_Height'] = 1.5\n",
    "        df.loc[df['Story_Height'] == 'C', 'Story_Height'] = 2\n",
    "        df.loc[df['Story_Height'] == 'D', 'Story_Height'] = 2.5\n",
    "        df.loc[df['Story_Height'] == 'E', 'Story_Height'] = 3\n",
    "        df.loc[df['Story_Height'] == 'F', 'Story_Height'] = 3.5\n",
    "        df.loc[df['Story_Height'] == 'G', 'Story_Height'] = 4\n",
    "        df.loc[df['Story_Height'] == 'H', 'Story_Height'] = 5\n",
    "        df.loc[df['Story_Height'] == 'I', 'Story_Height'] = 1.75\n",
    "        df.loc[df['Story_Height'] == 'J', 'Story_Height'] = 1.4\n",
    "        df.loc[df['Story_Height'] == 'K', 'Story_Height'] = 1.63\n",
    "        df.loc[df['Story_Height'] == 'L', 'Story_Height'] = 1.88\n",
    "        df.loc[df['Story_Height'] == 'M', 'Story_Height'] = 2.4\n",
    "        df.loc[df['Story_Height'] == 'N', 'Story_Height'] = 2.63\n",
    "        df.loc[df['Story_Height'] == 'O', 'Story_Height'] = 2.75\n",
    "        print(\"Story height is converted successfully\")\n",
    "        return df\n",
    "    \n",
    "def filter_column(\n",
    "                df, filter_column, \n",
    "                city_list=None, filter_date=None):\n",
    "    \"\"\"Filter dataframe by city and date\n",
    "    \n",
    "    Args:\n",
    "        df (dataframe): dataframe\n",
    "        filter_column (str): filter column\n",
    "        city_list (list): list of cities (default: None)\n",
    "        filter_date (str): filter date (default: None)\n",
    "    \"\"\"\n",
    "    if filter_column == 'TYPE_AND_USE':\n",
    "        # According to the U.S. Census Bureau, a single-family house is one that may be fully detached, semi-detached, a row house or a townhome. df.loc[df['column_name'].isin(some_values)]\n",
    "        df = df.loc[df[filter_column].isin([1, 8])]\n",
    "        print(f\"{filter_column} is filtered successfully\")\n",
    "    elif filter_column == 'PHYSICAL_CITY':\n",
    "        if city_list is None:\n",
    "            print(\"Please provide city list\")\n",
    "            print(\"Stop filtering\")\n",
    "        else:\n",
    "            df = df.drop(df[~df[filter_column].isin(city_list)].index)\n",
    "            df[filter_column] = df[filter_column].str.lower()\n",
    "            print(f\"{filter_column} is filtered successfully\")\n",
    "    elif filter_column == 'Deed_Date':\n",
    "        if filter_date is None:\n",
    "            print(\"Please provide date\")\n",
    "            print(\"Stop filtering\")\n",
    "        else:\n",
    "            df = df.loc[df[filter_column] > filter_date]\n",
    "            df.drop(columns=['Remodeled_Year', ], inplace=True)\n",
    "            df.reset_index(drop=True, inplace=True)\n",
    "            print(f\"{filter_column} is filtered successfully\")\n",
    "            print(\"Remodeled_Year is removed\")\n",
    "            print(\"Index of dataframe is reset\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_zipcode(df, update_location):\n",
    "    df.loc[(df['PHYSICAL_ZIP_CODE'] == 0) & (df['Planning_Jurisdiction'] == 'CA'), 'PHYSICAL_CITY'] = 'cary'\n",
    "    df.loc[(df['PHYSICAL_ZIP_CODE'] == 0) & (df['Planning_Jurisdiction'] == 'RA'), 'PHYSICAL_CITY'] = 'raleigh'\n",
    "    df.loc[(df['PHYSICAL_ZIP_CODE'] == 0) & (df['Planning_Jurisdiction'] == 'WE'), 'PHYSICAL_CITY'] = 'wendell'\n",
    "    df.loc[(df['PHYSICAL_ZIP_CODE'] == 0) & (df['Planning_Jurisdiction'] == 'ZB'), 'PHYSICAL_CITY'] = 'zebulon'\n",
    "    df.loc[(df['PHYSICAL_ZIP_CODE'] == 0) & (df['Planning_Jurisdiction'] == 'WF'), 'PHYSICAL_CITY'] = 'wake forest'\n",
    "    df['address'] = df['Street_Number'].astype(str) + \" \" + df['Street_Name'] + \" \" + \\\n",
    "        df['Street_Type'] + \", \" + df['PHYSICAL_CITY']\n",
    "\n",
    "    geolocator = Nominatim(user_agent=\"myGeocoder\")\n",
    "\n",
    "    addresses = df[df['PHYSICAL_ZIP_CODE'] == 0]['address'].tolist()\n",
    "    location_dict = {}\n",
    "    location_lst = []\n",
    "    for address in addresses:\n",
    "        location_dict[address] = None\n",
    "        location = geolocator.geocode(address)\n",
    "        if location != None:\n",
    "            location_dict[address] = location.address.split(',')[-2]\n",
    "        else: \n",
    "            print(f\"{address} is not found\")\n",
    "    non_location = {}\n",
    "    for address, zip in location_dict.items():\n",
    "        if location_dict[address] is None:\n",
    "            # print(address)\n",
    "            non_location[address] = None\n",
    "    location_dict.update(update_location)\n",
    "\n",
    "    for key, value in location_dict.items():\n",
    "        df.loc[df['address'] == key, 'PHYSICAL_ZIP_CODE'] = value\n",
    "    print(\"ALL missing zipcodes are found successfully\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliso\\AppData\\Local\\Temp/ipykernel_50428/2274136405.py:8: DtypeWarning: Columns (47,70,71,72,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(432976, 87)\n",
      "The data is loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# read csv file\n",
    "house_price_df = read_csv(house_file_path, print_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Remodeled_Year is converted successfully\n",
      "Deed_Date is converted successfully\n",
      "Number of nan values of PHYSICAL_ZIP_CODE is 0\n",
      "Number of nan values of HEATED_AREA is 0\n",
      "Land_Sale_Price is converted successfully\n",
      "Total_sale_Price is converted successfully\n",
      "Assessed_Building_Value is converted successfully\n"
     ]
    }
   ],
   "source": [
    "updated_house_price = used_columns_df(house_price_df, used_columns_list)\n",
    "updated_house_price = format_date(updated_house_price, 'Remodeled_Year')\n",
    "updated_house_price = format_date(updated_house_price, 'Deed_Date')\n",
    "updated_house_price = fill_drop_na(updated_house_price, 'PHYSICAL_ZIP_CODE')\n",
    "updated_house_price = fill_drop_na(updated_house_price, 'HEATED_AREA')\n",
    "updated_house_price = format_price_value(updated_house_price, 'Land_Sale_Price', \n",
    "                                        'float', replace=True)\n",
    "updated_house_price = format_price_value(updated_house_price, 'Total_sale_Price', \n",
    "                                        'float', replace=True)\n",
    "updated_house_price = format_price_value(updated_house_price, 'Assessed_Building_Value', \n",
    "                                        'float', replace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bathroom number is converted successfully\n",
      "Story height is converted successfully\n",
      "TYPE_AND_USE is filtered successfully\n",
      "PHYSICAL_CITY is filtered successfully\n",
      "(335542, 17)\n"
     ]
    }
   ],
   "source": [
    "updated_house_price = convert_categorical_to_numeric_variables(updated_house_price, 'BATH')\n",
    "updated_house_price = convert_categorical_to_numeric_variables(updated_house_price, 'Story_Height')\n",
    "\n",
    "updated_house_price = filter_column(updated_house_price, 'TYPE_AND_USE')\n",
    "updated_house_price = filter_column(updated_house_price, 'PHYSICAL_CITY', wake_cities)\n",
    "print(updated_house_price.shape)\n",
    "# updated_house_price.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zero values of Total_sale_Price is 0\n",
      "Deed_Date is filtered successfully\n",
      "Remodeled_Year is removed\n",
      "Index of dataframe is reset\n",
      "None value in UTILITIES is dropped successfully\n",
      "Index of the dataframe is reset successfully\n",
      "None value in BATH is dropped successfully\n",
      "Index of the dataframe is reset successfully\n",
      "None value in Story_Height is dropped successfully\n",
      "Index of the dataframe is reset successfully\n",
      "(278913, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliso\\AppData\\Local\\Temp/ipykernel_50428/2274136405.py:169: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.drop(columns=['Remodeled_Year', ], inplace=True)\n",
      "C:\\Users\\aliso\\AppData\\Local\\Temp/ipykernel_50428/2274136405.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=[column], inplace=True)\n",
      "C:\\Users\\aliso\\AppData\\Local\\Temp/ipykernel_50428/2274136405.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=[column], inplace=True)\n",
      "C:\\Users\\aliso\\AppData\\Local\\Temp/ipykernel_50428/2274136405.py:63: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df.dropna(subset=[column], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "updated_house_price = remove_zero(updated_house_price, 'Total_sale_Price')\n",
    "updated_house_price = filter_column(updated_house_price, 'Deed_Date', filter_date=\"2000-01-01\")\n",
    "updated_house_price = fill_drop_na(updated_house_price, 'UTILITIES')\n",
    "updated_house_price = fill_drop_na(updated_house_price, 'BATH')\n",
    "updated_house_price = fill_drop_na(updated_house_price, 'Story_Height')\n",
    "print(updated_house_price.shape)\n",
    "# updated_house_price"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fill out zero zip code values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliso\\AppData\\Local\\Temp/ipykernel_50428/1490224660.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['address'] = df['Street_Number'].astype(str) + \" \" + df['Street_Name'] + \" \" + \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5500 BATOUL LN, raleigh is not found\n",
      "1436 INDIGO CREEK DR, zebulon is not found\n",
      "1432 INDIGO CREEK DR, zebulon is not found\n",
      "1428 INDIGO CREEK DR, zebulon is not found\n",
      "1424 INDIGO CREEK DR, zebulon is not found\n",
      "1420 INDIGO CREEK DR, zebulon is not found\n",
      "1416 INDIGO CREEK DR, zebulon is not found\n",
      "1412 INDIGO CREEK DR, zebulon is not found\n",
      "1413 INDIGO CREEK DR, zebulon is not found\n",
      "1429 INDIGO CREEK DR, zebulon is not found\n",
      "1433 INDIGO CREEK DR, zebulon is not found\n",
      "1517 INDIGO CREEK DR, zebulon is not found\n",
      "1519 INDIGO CREEK DR, zebulon is not found\n",
      "1521 INDIGO CREEK DR, zebulon is not found\n",
      "1523 INDIGO CREEK DR, zebulon is not found\n",
      "1520 INDIGO CREEK DR, zebulon is not found\n",
      "1518 INDIGO CREEK DR, zebulon is not found\n",
      "1516 INDIGO CREEK DR, zebulon is not found\n",
      "529 BASIN HILL DR, wake forest is not found\n",
      "505 BASIN HILL DR, wake forest is not found\n",
      "501 BASIN HILL DR, wake forest is not found\n",
      "ALL missing zipcodes are found successfully\n"
     ]
    }
   ],
   "source": [
    "updated_house_price = find_zipcode(updated_house_price, update_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Land_Sale_Price              0\n",
       "Total_sale_Price             0\n",
       "Deed_Date                    0\n",
       "Assessed_Building_Value      0\n",
       "Story_Height                 0\n",
       "HEATED_AREA                  0\n",
       "UTILITIES                    0\n",
       "BATH                         0\n",
       "BATH_FIXTURES                0\n",
       "TYPE_AND_USE                 0\n",
       "PHYSICAL_ZIP_CODE            0\n",
       "PHYSICAL_CITY                0\n",
       "Street_Number                0\n",
       "Street_Name                  0\n",
       "Street_Type                929\n",
       "Planning_Jurisdiction        0\n",
       "address                    929\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "updated_house_price.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_price.to_csv('assets/updated_house_price.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72572667d892e1791183c326e3aa8bbc0ee980c8a9bf058479e648f1904c68bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
