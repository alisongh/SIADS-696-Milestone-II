{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\aliso\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "import missingno as msno\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "folder_path = \"assets\"\n",
    "sub_folder_path = \"crime_rate\"\n",
    "house_path = 'updated_house_price.csv'\n",
    "pop_growth_path_1 = 'population_growth_2000_2010.csv'\n",
    "pop_growth_path_2 = 'population_growth_2010-2020.csv'\n",
    "pop_growth_path_3 = 'population_growth_2020-2021.csv'\n",
    "unemploy_path = 'wake_unemployment.csv'\n",
    "covid_path = 'covid_confirmed.csv'\n",
    "mort_rate_path = 'mort_rate.csv'\n",
    "lumber_path = 'lumber.csv'\n",
    "metals_path = 'metals.csv'\n",
    "build_material_path = 'build_material.csv'\n",
    "int_rate_path = 'int_rate.csv'\n",
    "us_house_supply_path = 'HousingSupply.xlsx'\n",
    "us_house_demand_path = 'HAI.xlsx'\n",
    "wake_supply_path = 'market_hotness_supply_index.csv'\n",
    "wake_demand_path = 'market_hotness_demand_index.csv'\n",
    "\n",
    "crime_apex_path = 'apex.csv'\n",
    "crime_cary_path = 'cary.csv'\n",
    "crime_fuquay_varina_path = 'fuquay_varina.csv'\n",
    "crime_garner_path = 'garner.csv'\n",
    "crime_holly_springs_path = 'hollyspring.csv'\n",
    "crime_morrisville_path = 'morrisville.csv'\n",
    "crime_knightdale_path = 'knightdale.csv'\n",
    "crime_raleigh_path = 'raleigh.csv'\n",
    "crime_rolesville_path = 'rolesville.csv'\n",
    "crime_wake_forest_path = 'wake_forest.csv'\n",
    "crime_wendell_path = 'wendell.csv'\n",
    "crime_zenbulon_path = 'zenbulon.csv'\n",
    "# file extension\n",
    "csv = 'csv'\n",
    "xlsx = 'xlsx'\n",
    "# encoding type\n",
    "encoding_format='latin-1'\n",
    "\n",
    "# date format\n",
    "date_format_ym = '%Y-%m'\n",
    "date_format_y = '%Y'\n",
    "\n",
    "# add mortgage rate\n",
    "mort_rate_2022 = {'date': '2022-09', 'Rate': 6.82}\n",
    "\n",
    "# population growth\n",
    "state_name = 'North Carolina'\n",
    "state_short_name = 'NC'\n",
    "county_name = 'Wake County'\n",
    "# add population growth\n",
    "added_pop_growth = [\n",
    "                    {'year': '2000', 'pop_growth_rate': 0.018},\n",
    "                    {'year': '2022', 'pop_growth_rate': 0.025}\n",
    "                    ]\n",
    "pop_growth_drop_cols = [\n",
    "    'SUMLEV', 'REGION', 'DIVISION', \n",
    "    'STATE', 'COUNTY', 'STNAME'\n",
    "    ]\n",
    "pop_growth_range_one = \"2000-2010\"\n",
    "pop_growth_range_two = \"2011-2020\"\n",
    "pop_growth_range_three = \"2021-2022\"\n",
    "pop_growth_one_drop_cols = [\n",
    "    'ESTIMATESBASE2000', 'CENSUS2010POP', 'POPESTIMATE2000', \n",
    "    'POPESTIMATE2001', 'POPESTIMATE2002', 'POPESTIMATE2003', \n",
    "    'POPESTIMATE2004', 'POPESTIMATE2005', 'POPESTIMATE2006', \n",
    "    'POPESTIMATE2007', 'POPESTIMATE2008', 'POPESTIMATE2009', \n",
    "    'POPESTIMATE2010'\n",
    "    ]\n",
    "pop_growth_two_cols = [\n",
    "    'CTYNAME', 'rate_2011', 'rate_2012', \n",
    "    'rate_2013', 'rate_2014', 'rate_2015', \n",
    "    'rate_2016', 'rate_2017', 'rate_2018', \n",
    "    'rate_2019', 'rate_2020'\n",
    "    ]\n",
    "pop_growth_three_cols = ['CTYNAME', 'rate_2021']\n",
    "pop_growth_index_col = 'CTYNAME'\n",
    "\n",
    "pop_growth_one_rate_cols = [\n",
    "    'rate_2001', 'rate_2002', 'rate_2003',\n",
    "    'rate_2004', 'rate_2005', 'rate_2006',\n",
    "    'rate_2007', 'rate_2008', 'rate_2009',\n",
    "    'rate_2010'\n",
    "]\n",
    "pop_growth_two_rate_cols = [\n",
    "    'rate_2011', 'rate_2012', 'rate_2013',\n",
    "    'rate_2014', 'rate_2015', 'rate_2016',\n",
    "    'rate_2017', 'rate_2018', 'rate_2019',\n",
    "    'rate_2020'\n",
    "]\n",
    "pop_growth_three_rate_cols = ['rate_2021']\n",
    "\n",
    "pop_growth_one_year_cols = [\n",
    "    'POPESTIMATE2001', 'POPESTIMATE2002', 'POPESTIMATE2003',\n",
    "    'POPESTIMATE2004', 'POPESTIMATE2005', 'POPESTIMATE2006',\n",
    "    'POPESTIMATE2007', 'POPESTIMATE2008', 'POPESTIMATE2009',\n",
    "    'POPESTIMATE2010'\n",
    "]\n",
    "pop_growth_two_year_cols = [\n",
    "    'POPESTIMATE2011', 'POPESTIMATE2012', 'POPESTIMATE2013',\n",
    "    'POPESTIMATE2014', 'POPESTIMATE2015', 'POPESTIMATE2016',\n",
    "    'POPESTIMATE2017', 'POPESTIMATE2018', 'POPESTIMATE2019',\n",
    "    'POPESTIMATE2020'\n",
    "]\n",
    "pop_growth_three_year_cols = ['POPESTIMATE2020', 'POPESTIMATE2021']\n",
    "# covid case\n",
    "start_date = '2000-01-01'\n",
    "covid_date = '2020-01-21'\n",
    "end_date = '2022-09-15'\n",
    "# raw materials\n",
    "material_date = '2000-01'\n",
    "material_lumber = 'lumber'\n",
    "material_metal = 'metal'\n",
    "material_build = 'building'\n",
    "raw_material_date_col = 'date'\n",
    "lumber_price_col = 'lumber_price'\n",
    "metals_price_col = 'metals_price'\n",
    "build_material_price_col = 'build_price'\n",
    "# interest rate\n",
    "country_name = 'USA'\n",
    "int_rate_date = '2000-01'\n",
    "int_rate_drop_cols = ['Country Name', 'Indicator Name', 'Indicator Code']\n",
    "int_rate_save_path = 'us_int_rate.csv'\n",
    "# house market\n",
    "us_house_date = '2000-01'\n",
    "us_house_supply_name = 'supply'\n",
    "us_house_demand_name = 'demand'\n",
    "us_house_start_date = '2000-01-01'\n",
    "us_house_end_date = '2021-12-31'\n",
    "date_list = [\n",
    "    '2017-01', '2017-02', '2017-03', '2017-04', \n",
    "    '2017-05', '2017-06', '2017-07'\n",
    "    ]\n",
    "wake_supply_name = 'wake_supply_index'\n",
    "wake_demand_name = 'wake_demand_index'\n",
    "# crime data\n",
    "apex_city = 'apex'\n",
    "cary_city = 'cary'\n",
    "fuquay_varina_city = 'fuquay_varina'\n",
    "garner_city = 'garner'\n",
    "holly_springs_city = 'hollyspring'\n",
    "morrisville_city = 'morrisville'\n",
    "knightdale_city = 'knightdale'\n",
    "raleigh_city = 'raleigh'\n",
    "rolesville_city = 'rolesville'\n",
    "wake_forest_city = 'wake_forest'\n",
    "wendell_city = 'wendell'\n",
    "zenbulon_city = 'zenbulon'\n",
    "\n",
    "# add missing crime data\n",
    "apex_added_year = 2007\n",
    "knightdale_added_year = [2002, 2003]\n",
    "hollysprings_added_year = 2008\n",
    "raleigh_added_year = [2015,2016,2017]\n",
    "rolesville_added_year = 2008\n",
    "wake_forest_added_year = 2000\n",
    "zenbulon_added_year = 2000\n",
    "\n",
    "apex_start = 0\n",
    "apex_end = 7\n",
    "knightdale_start = [0,1]\n",
    "knightdale_end = [4,5]\n",
    "hollysprings_start = 6\n",
    "hollysprings_end = 10\n",
    "raleigh_start = [12,13,14]\n",
    "raleigh_end = [15,16,17]\n",
    "rolesville_start=4\n",
    "rolesville_end=8\n",
    "wake_forest_start=0\n",
    "wake_forest_end=4\n",
    "zenbulon_start=0\n",
    "zenbulon_end=4\n",
    "# final data\n",
    "removed_column = [\n",
    "    'type_and_use','street_number', 'street_name', \n",
    "    'street_type', 'planning_jurisdiction', 'address'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def namestr(obj, namespace):\n",
    "    \"\"\"Extract variable name from namespace\"\"\"\n",
    "    return [name for name in namespace if namespace[name] is obj]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(\n",
    "    file_ext, file_path, folder_path, sub_folder_path=None, \n",
    "    print_columns=False, encoding=None, sheet_name=None):\n",
    "    \"\"\"Read file based on file extension\n",
    "    \n",
    "    Args:\n",
    "        file_ext (str): file extension\n",
    "        file_path (str): file path\n",
    "        print_columns (bool, optional): print columns. Defaults to False.\n",
    "        encoding (str, optional): encoding. Defaults to None.\n",
    "        sheet_name (str, optional): sheet name. Defaults to None.\n",
    "    \"\"\"\n",
    "    if sub_folder_path == None:\n",
    "        new_file_path = os.path.join(folder_path, file_path)\n",
    "    else:\n",
    "        new_file_path = os.path.join(folder_path, sub_folder_path, file_path)\n",
    "    if file_ext == 'csv':\n",
    "        if encoding != None:\n",
    "            df = pd.read_csv(new_file_path, encoding=encoding)\n",
    "        else:\n",
    "            df = pd.read_csv(new_file_path)\n",
    "    elif file_ext == 'xlsx':\n",
    "        if sheet_name != None:\n",
    "            df = pd.read_excel(new_file_path, sheet_name=sheet_name)\n",
    "        else:\n",
    "            df = pd.read_excel(new_file_path)\n",
    "    if print_columns:\n",
    "        print(df.columns)\n",
    "    if sheet_name != None:\n",
    "        print(f\"The data {namestr(file_path, globals())}, \\\n",
    "            {sheet_name} sheet is loaded successfully!\")\n",
    "    else:\n",
    "        print(f\"The data {namestr(file_path, globals())} is loaded successfully!\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mortgage_rate_df(house_df, mort_rate_df, added_mort_rate=None):\n",
    "    \"\"\"Add mortgage rate to house dataframe\n",
    "    \n",
    "    Args:\n",
    "        house_df (dataframe): house dataframe\n",
    "        mort_rate_df (dataframe): mortgage rate dataframe\n",
    "        added_mort_rate (dict, optional): missing mortgage rate. Defaults to None.\n",
    "    \"\"\"\n",
    "    mort_rate_df.rename(columns={'Unnamed: 0': 'date'}, inplace=True)\n",
    "    mort_rate_df['date'] = pd.to_datetime(mort_rate_df['date'])\n",
    "    mort_rate_df['date'] = mort_rate_df['date'].dt.strftime(date_format_ym)\n",
    "    if added_mort_rate != None:\n",
    "        mort_rate_df = mort_rate_df.append(added_mort_rate, ignore_index=True)\n",
    "        print(f\"The new mortgage rate data \\\n",
    "             {namestr(added_mort_rate, globals())[0]} is added successfully!\")\n",
    "    else:\n",
    "        pass\n",
    "    house_df['Deed_Date'] = pd.to_datetime(house_df['Deed_Date'])\n",
    "    house_df['Deed_Date'] = house_df['Deed_Date'].dt.strftime(date_format_ym)\n",
    "    house_df.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "\n",
    "    updated_house_df = house_df.merge(mort_rate_df, left_on='Deed_Date', right_on='date', how='left')\n",
    "    updated_house_df.rename(columns={'Rate': 'mort_rate'}, inplace=True)\n",
    "    updated_house_df.drop(columns=['date'], inplace=True)\n",
    "    updated_house_df.columns = map(str.lower, updated_house_df.columns)\n",
    "    print(updated_house_df.shape)\n",
    "    print(f\"The mortgage rate data is merged successfully!\")\n",
    "    return updated_house_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unemployment_rate_df(unemployment_df, updated_house_df):\n",
    "    \"\"\"Add unemployment rate to house dataframe    \n",
    "    \n",
    "    Args:\n",
    "        unemployment_df (dataframe): unemployment dataframe\n",
    "        updated_house_df (dataframe): house dataframe\n",
    "    \"\"\"\n",
    "    unemployment_df['Year'] = unemployment_df['Year'].astype(str)\n",
    "    unemployment_df['Month'] = unemployment_df['Month'].astype(str)\n",
    "    unemployment_df['date'] = unemployment_df['Year'] + '-' + unemployment_df['Month']\n",
    "    unemployment_df['date'] = pd.to_datetime(unemployment_df['date'])\n",
    "    unemployment_df['date'] = unemployment_df['date'].dt.strftime(date_format_ym)\n",
    "    unemployment_df.rename(columns={'Unemployment Rate(%)': 'unemploy_rate'}, inplace=True)\n",
    "    unemployment_df = unemployment_df[['date', 'unemploy_rate']].copy()\n",
    "    \n",
    "    updated_house_df = updated_house_df.merge(unemployment_df, left_on='deed_date', right_on='date', how='left')\n",
    "    updated_house_df.drop(columns=['date'], inplace=True)\n",
    "    print(updated_house_df.shape)\n",
    "    print(f\"The unemployment rate data is merged successfully!\")\n",
    "    return updated_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_population_growth_df(\n",
    "    population_growth_df, updated_house_df, state_name, \n",
    "    county_name, year_range):\n",
    "    \"\"\"Pre process population growth dataframes by city\n",
    "    Removed unnecessary columns and rows\n",
    "    Calculate population growth rate\n",
    "    Combine population growth rates by year\n",
    "    \n",
    "    Args:\n",
    "        population_growth_df (dataframe): population growth dataframe\n",
    "        updated_house_df (dataframe): house dataframe\n",
    "        state_name (str): state name\n",
    "        county_name (str): county name\n",
    "        year_range (list): year range\n",
    "    \"\"\"\n",
    "    population_growth_df = population_growth_df.loc[population_growth_df['STNAME'] == state_name]\n",
    "    population_growth_df = population_growth_df.loc[population_growth_df['CTYNAME'] == county_name]\n",
    "    population_growth_df.drop(columns=pop_growth_drop_cols, inplace=True)\n",
    "    \n",
    "    if year_range == pop_growth_range_one:\n",
    "        for rate_item in range(len(pop_growth_one_rate_cols)):\n",
    "            for pop_item in range(0, len(pop_growth_one_year_cols)-1):\n",
    "                population_growth_df[pop_growth_one_rate_cols[rate_item]] = (population_growth_df[pop_growth_one_year_cols[pop_item + 1]] - population_growth_df[pop_growth_one_year_cols[pop_item]]) / population_growth_df[pop_growth_one_year_cols[pop_item]]\n",
    "        \n",
    "        population_growth_df.drop(columns=pop_growth_one_drop_cols, inplace=True)\n",
    "        population_growth_df.set_index(pop_growth_index_col, inplace=True)\n",
    "    elif year_range == pop_growth_range_two:\n",
    "        for rate_item in range(len(pop_growth_two_rate_cols)):\n",
    "            for pop_item in range(0, len(pop_growth_two_year_cols)-1):\n",
    "                population_growth_df[pop_growth_two_rate_cols[rate_item]] = (population_growth_df[pop_growth_two_year_cols[pop_item + 1]] - population_growth_df[pop_growth_two_year_cols[pop_item]]) / population_growth_df[pop_growth_two_year_cols[pop_item]]\n",
    "        \n",
    "        population_growth_df = population_growth_df[pop_growth_two_cols].copy()\n",
    "        population_growth_df.set_index(pop_growth_index_col, inplace=True)\n",
    "    elif year_range == pop_growth_range_three:\n",
    "        for rate_item in range(len(pop_growth_three_rate_cols)):\n",
    "            for pop_item in range(0, len(pop_growth_three_year_cols)-1):\n",
    "                population_growth_df[pop_growth_three_rate_cols[rate_item]] = (population_growth_df[pop_growth_three_year_cols[pop_item + 1]] - population_growth_df[pop_growth_three_year_cols[pop_item]]) / population_growth_df[pop_growth_three_year_cols[pop_item]]\n",
    "        \n",
    "        population_growth_df = population_growth_df[pop_growth_three_cols].copy()\n",
    "        population_growth_df.set_index(pop_growth_index_col, inplace=True)\n",
    "    print(f\"Population growth data {year_range} has been processed successfully\")\n",
    "    return population_growth_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_pop_growth_df(\n",
    "    pop_growth_df_1, pop_growth_df_2, pop_growth_df_3, \n",
    "    updated_house_df, added_pop_growth=None):\n",
    "    \"\"\"Combine population growth dataframe with housing dataframe\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    pop_growth_df_1 : pandas dataframe\n",
    "        Population growth dataframe for 2000-2010\n",
    "    pop_growth_df_2 : pandas dataframe\n",
    "        Population growth dataframe for 2011-2020\n",
    "    pop_growth_df_3 : pandas dataframe\n",
    "        Population growth dataframe for 2021\n",
    "    updated_house_df : pandas dataframe\n",
    "        Housing dataframe with population growth data\n",
    "    added_pop_growth : pandas dataframe, optional\n",
    "    \"\"\"\n",
    "    pop_growth_df = pd.concat([pop_growth_df_1, pop_growth_df_2, pop_growth_df_3], axis=1)\n",
    "    final_pop_growth = pop_growth_df.transpose()\n",
    "    final_pop_growth.reset_index(inplace=True)\n",
    "    final_pop_growth.rename(columns={'index':'year', 'Wake County':'pop_growth_rate'}, inplace=True)\n",
    "    final_pop_growth['year'] = final_pop_growth['year'].str.split('_').str[1]\n",
    "    final_pop_growth['year'] = pd.to_datetime(final_pop_growth['year'], format=date_format_y)\n",
    "    final_pop_growth['year'] = final_pop_growth['year'].dt.strftime(date_format_y)\n",
    "\n",
    "    final_pop_growth.rename_axis(None, axis=1, inplace=True)\n",
    "    if added_pop_growth != None:\n",
    "        final_pop_growth = final_pop_growth.append(added_pop_growth, ignore_index=True)\n",
    "    final_pop_growth.sort_values(by='year', inplace=True)\n",
    "    final_pop_growth.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    updated_house_df['year'] = pd.to_datetime(updated_house_df['deed_date']).dt.year\n",
    "    updated_house_df['year'] = updated_house_df['year'].astype(str)\n",
    "    updated_house_df = updated_house_df.merge(final_pop_growth, left_on='year', right_on='year', how='left')\n",
    "    updated_house_df.drop(columns=['year'], inplace=True)\n",
    "    print(\"Population growth data has been merged successfully\")\n",
    "    print(updated_house_df.shape)\n",
    "    return updated_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_covid_df(\n",
    "    covid_df, updated_house_df, state_short_name, county_name, \n",
    "    start_date, covid_date, end_date, freq='D'):\n",
    "    \"\"\"Pre processing covid case dataframe\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    covid_df : pandas dataframe\n",
    "        Covid case dataframe\n",
    "    updated_house_df : pandas dataframe\n",
    "        Housing dataframe\n",
    "    state_short_name : str \n",
    "        State short name\n",
    "    county_name : str  \n",
    "        County full name\n",
    "    start_date : str\n",
    "        Start date\n",
    "    covid_date : str\n",
    "        Covid date\n",
    "    end_date : str\n",
    "        End date\n",
    "    freq : str, optional\n",
    "    \"\"\"\n",
    "    county_name = county_name.replace(\"County\", \"County \")\n",
    "    nc_covid = covid_df.loc[covid_df['State'] == state_short_name]\n",
    "    wake_covid = nc_covid.loc[nc_covid['County Name'] == county_name]\n",
    "    wake_covid.drop(columns=[\n",
    "        'countyFIPS', 'StateFIPS', \n",
    "        'State', 'County Name'\n",
    "        ], inplace=True)\n",
    "\n",
    "    updated_covid_df = pd.DataFrame()\n",
    "    updated_covid_df['date'] = pd.date_range(start=start_date, end=end_date, freq=freq)\n",
    "\n",
    "    final_wake_covid = wake_covid.transpose()\n",
    "    final_wake_covid.reset_index(inplace=True)\n",
    "    # print(final_wake_covid.columns[1])\n",
    "    final_wake_covid.rename(columns={'index':'date', final_wake_covid.columns[1]:'covid_cases'}, inplace=True)\n",
    "    final_wake_covid['date'] = pd.to_datetime(final_wake_covid['date'])\n",
    "\n",
    "    final_covid_df = updated_covid_df.merge(final_wake_covid, left_on='date', right_on='date', how='left')\n",
    "    final_covid_df['covid_cases'].replace(to_replace=0, method='ffill', inplace=True)\n",
    "    final_covid_df['covid_cases'].fillna(method='ffill', inplace=True)\n",
    "    final_covid_df.loc[final_covid_df['date'] < covid_date, 'covid_cases'] = 0\n",
    "    \n",
    "\n",
    "    return final_covid_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_covid_df(updated_house_df, pre_covid_df, covid_date):\n",
    "    \"\"\"Combine covid case dataframe with housing dataframe\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    updated_house_df : pandas dataframe\n",
    "        Housing dataframe\n",
    "    pre_covid_df : pandas dataframe\n",
    "        Pre processed covid case dataframe\n",
    "    \"\"\"\n",
    "    updated_house_df['deed_date'] = pd.to_datetime(updated_house_df['deed_date'])\n",
    "\n",
    "    # set covid case to 0 for all dates before covid started 2020-01-21\n",
    "    updated_house_df['covid_cases'] = 0\n",
    "    updated_house_df.set_index('deed_date', inplace=True)\n",
    "    updated_house_df.update(pre_covid_df.set_index('date'))\n",
    "    updated_house_df['is_covid'] = 0\n",
    "    updated_house_df.loc[updated_house_df['covid_cases'] > 0, 'is_covid'] = 1\n",
    "    updated_house_df.reset_index(inplace=True)\n",
    "    \n",
    "\n",
    "    print(updated_house_df.shape)\n",
    "    print(\"Covid data has been merged successfully\")\n",
    "    return updated_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def raw_material_df(material_name, material_df, date):\n",
    "    \"\"\"Pre processing raw material dataframe\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    material_name : str\n",
    "        Raw material name\n",
    "    material_df : pandas dataframe\n",
    "        Raw material dataframe\n",
    "    date : str\n",
    "        Date after 2000\n",
    "    \"\"\"\n",
    "    if material_name == 'lumber':\n",
    "        material_df.rename(columns={'DATE':raw_material_date_col, 'WPU081':lumber_price_col}, inplace=True)\n",
    "        material_df[raw_material_date_col] = pd.to_datetime(material_df[raw_material_date_col])\n",
    "        material_df[raw_material_date_col] = material_df[raw_material_date_col].dt.strftime(date_format_ym)\n",
    "        material_df = material_df[material_df[raw_material_date_col] >= date]\n",
    "        material_df.reset_index(drop=True, inplace=True)\n",
    "    elif material_name == 'metal':\n",
    "        material_df.rename(columns={'DATE':raw_material_date_col, 'WPU101':metals_price_col}, inplace=True)\n",
    "        material_df[raw_material_date_col] = pd.to_datetime(material_df[raw_material_date_col])\n",
    "        material_df[raw_material_date_col] = material_df[raw_material_date_col].dt.strftime(date_format_ym)\n",
    "        material_df = material_df[material_df[raw_material_date_col] >= date]\n",
    "        material_df.reset_index(drop=True, inplace=True)\n",
    "    elif material_name == 'building':\n",
    "        material_df.rename(columns={'DATE':raw_material_date_col, 'PCU44414441':build_material_price_col}, inplace=True)\n",
    "        material_df[raw_material_date_col] = pd.to_datetime(material_df[raw_material_date_col])\n",
    "        material_df[raw_material_date_col] = material_df[raw_material_date_col].dt.strftime(date_format_ym)\n",
    "        material_df = material_df[material_df[raw_material_date_col] >= date]\n",
    "        material_df.reset_index(drop=True, inplace=True)\n",
    "    else:\n",
    "        return print(\"You want to process a new material, please let me have a look before processing\")\n",
    "        \n",
    "    print(f\"Raw material {material_name} data has been processed successfully\")\n",
    "    return material_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_material_df(\n",
    "    material_df_1, material_df_2, \n",
    "    material_df_3, updated_house_df):\n",
    "    \"\"\"Combine raw material dataframe with housing dataframe\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    material_df_1 : pandas dataframe\n",
    "        Lumber dataframe\n",
    "    material_df_2 : pandas dataframe\n",
    "        Metals dataframe\n",
    "    material_df_3 : pandas dataframe\n",
    "        Building materials dataframe\n",
    "    updated_house_df : pandas dataframe\n",
    "        Housing dataframe\n",
    "    \"\"\"\n",
    "    lumber_metals_df = material_df_1.merge(material_df_2, left_on='date', right_on='date', how='left')\n",
    "\n",
    "    # updated_house_df['deed_date'] = pd.to_datetime(updated_house_df['deed_date'])\n",
    "    # updated_house_df['deed_date'] = updated_house_df['deed_date'].dt.strftime(date_format_ym)\n",
    "    final_material_df = lumber_metals_df.merge(material_df_3, left_on='date', right_on='date', how='left')\n",
    "    final_material_df.fillna(0, inplace=True)\n",
    "    final_material_df['date'] = pd.to_datetime(final_material_df['date'])\n",
    "\n",
    "    updated_house_df = updated_house_df.merge(final_material_df, left_on='deed_date', right_on='date', how='left')\n",
    "    updated_house_df.drop(columns=['date'], inplace=True)\n",
    "    print(f\"Material data has been merged successfully\")\n",
    "    print(updated_house_df.shape)\n",
    "    return updated_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_build_price(df):\n",
    "    df['year'] = df['date'].str.split('-', expand=True)[0]\n",
    "    avg_build_price = df.groupby('year')['build_price'].mean()[1] # get 2004 avg price\n",
    "    for year in range(2000, 2004):\n",
    "        if year == 2003:\n",
    "            for month in range(1, 12):\n",
    "                if month >= 10:\n",
    "                    df = df.append({'date': f'{year}-{month}', 'build_price': avg_build_price}, ignore_index=True)\n",
    "                else:\n",
    "                    df = df.append({'date': f'{year}-0{month}', 'build_price': avg_build_price}, ignore_index=True)\n",
    "        else: \n",
    "            for month in range(1, 13):\n",
    "                if month >= 10:\n",
    "                    df = df.append({'date': f'{year}-{month}', 'build_price': avg_build_price}, ignore_index=True)\n",
    "                else:\n",
    "                    df = df.append({'date': f'{year}-0{month}', 'build_price': avg_build_price}, ignore_index=True)\n",
    "    df.drop(columns=['year'], inplace=True)\n",
    "    df.sort_values(by='date', inplace=True)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def interest_rate_df(\n",
    "    int_rate_df, updated_house_df, \n",
    "    country_name, date):\n",
    "    \"\"\"Pre processing interest rate dataframe\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    int_rate_df : pandas dataframe\n",
    "        Interest rate dataframe\n",
    "    updated_house_df : pandas dataframe\n",
    "        Housing dataframe\n",
    "    country_name : str\n",
    "        Country short name\n",
    "    date : str\n",
    "        Date after 2000\n",
    "    \"\"\"\n",
    "    int_rate_df.drop(labels=[0,1,2], axis=0, inplace=True)\n",
    "    int_rate_df.columns = int_rate_df.iloc[0]\n",
    "    int_rate_df.drop(labels=[3], axis=0, inplace=True)\n",
    "    int_rate_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    us_int_rate_df = int_rate_df.loc[int_rate_df['Country Code'] == country_name]\n",
    "    us_int_rate_df.drop(columns=int_rate_drop_cols, inplace=True)\n",
    "    us_int_rate_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    us_int_rate_df = us_int_rate_df.transpose()\n",
    "    new_header = us_int_rate_df.iloc[0] #grab the first row for the header\n",
    "    us_int_rate_df = us_int_rate_df[1:] #take the data less the header row\n",
    "    us_int_rate_df.columns = new_header #set the header row as the df header\n",
    "    us_int_rate_df.reset_index(inplace=True)\n",
    "    us_int_rate_df.rename(columns={3:'date', country_name:'int_rate'}, inplace=True)\n",
    "    us_int_rate_df['date'] = us_int_rate_df['date'].astype(str)\n",
    "    us_int_rate_df['year'] = us_int_rate_df['date'].str.split('.',0).str[0]\n",
    "    us_int_rate_df['year'] = pd.to_datetime(us_int_rate_df['year'])\n",
    "    us_int_rate_df['year'] = us_int_rate_df['year'].dt.strftime(date_format_ym)\n",
    "    us_int_rate_df.drop(columns=['date'], inplace=True)\n",
    "    us_int_rate_df = us_int_rate_df.rename_axis(None, axis=1)\n",
    "    us_int_rate_final = us_int_rate_df.loc[us_int_rate_df['year'] >= date]\n",
    "    us_int_rate_final['year'] = pd.to_datetime(us_int_rate_final['year'])\n",
    "    us_int_rate_final['year'] = us_int_rate_final['year'].dt.strftime(date_format_y)\n",
    "    us_int_rate_final.to_csv(os.path.join(folder_path, int_rate_save_path))\n",
    "\n",
    "    updated_house_df['year'] = updated_house_df['deed_date'].dt.strftime(date_format_y)\n",
    "    updated_house_df['year'] = pd.to_datetime(updated_house_df['year'])\n",
    "    updated_house_df['year'] = updated_house_df['deed_date'].dt.strftime(date_format_y)\n",
    "    updated_house_df = updated_house_df.merge(us_int_rate_final, left_on='year', right_on='year', how='right')\n",
    "    updated_house_df.drop(columns=['year'], inplace=True)\n",
    "    print(f\"Interest rate data has been merged successfully\")\n",
    "    print(updated_house_df.shape)\n",
    "    return updated_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def us_house_market(house_market_df, market_name, date):\n",
    "    \"\"\"Pre processing US housing market dataframe\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    house_market_df : pandas dataframe\n",
    "        Housing market dataframe\n",
    "    market_name : str\n",
    "        Housing market name: supply or demand\n",
    "    date : str\n",
    "        Date after 2000\n",
    "    \"\"\"\n",
    "    if market_name == 'supply':\n",
    "        house_market_df.drop(columns=['DealInvt_US'], inplace=True)\n",
    "        house_market_df.rename(columns={'Year':'date', 'Shipments_US': market_name}, inplace=True)\n",
    "    elif market_name == 'demand':\n",
    "        house_market_df = house_market_df[['Year', 'FIXED_US']]\n",
    "        house_market_df.rename(columns={'Year':'date', 'FIXED_US': market_name}, inplace=True)\n",
    "    else: \n",
    "        return print(\"You entered wrong market name. Please check.\")\n",
    "\n",
    "    house_market_df['date'] = house_market_df['date'].astype(str)\n",
    "    house_market_df['date'] = pd.to_datetime(house_market_df['date'])\n",
    "    house_market_df['date'] = house_market_df['date'].dt.strftime(date_format_ym)\n",
    "    house_market_df = house_market_df[house_market_df['date'] >= date]\n",
    "    house_market_df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"{market_name} data has been processed successfully\")\n",
    "    return house_market_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_us_house_market(\n",
    "    house_market_df_supply, house_market_df_demand, supply_name, \n",
    "    demand_name, start_date, end_date, freq='MS'):\n",
    "    \"\"\"Combine US housing market dataframes\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    house_market_df_supply : pandas dataframe\n",
    "        US Housing market supply dataframe\n",
    "    house_market_df_demand : pandas dataframe\n",
    "        US Housing market demand dataframe\n",
    "    supply_name : str\n",
    "        US Housing market supply name\n",
    "    demand_name : str\n",
    "        US Housing market demand name\n",
    "    start_date : str\n",
    "        Start date\n",
    "    end_date : str\n",
    "        End date\n",
    "    freq : str (default: 'MS')\n",
    "        Frequency\n",
    "    \"\"\"\n",
    "    # import pandas as pd\n",
    "    # date_format_ym = '%Y-%m'\n",
    "    us_house_supply_demand_df = house_market_df_supply.merge(house_market_df_demand, \n",
    "                                                            left_on='date', \n",
    "                                                            right_on='date', \n",
    "                                                            how='left')\n",
    "    us_house_supply_demand_df.sort_values(by='date', inplace=True)\n",
    "    us_house_supply_demand_df = pd.DataFrame(np.repeat(us_house_supply_demand_df.values, 12, axis=0))\n",
    "    us_house_supply_demand_df.rename(columns={0:'date', 1:supply_name, 2:demand_name}, inplace=True)\n",
    "    \n",
    "    date_df = pd.DataFrame({'date': pd.date_range(start=start_date, end=end_date, freq=freq)})\n",
    "    us_house_supply_demand_df['new_date'] = date_df['date'].dt.strftime(date_format_ym)\n",
    "    us_house_supply_demand_df.drop(columns=['date'], inplace=True)\n",
    "    us_house_supply_demand_df.rename(columns={'new_date':'date'}, inplace=True)\n",
    "    final_us_house_supply_demand = us_house_supply_demand_df[[\n",
    "                                                    'date', \n",
    "                                                    supply_name, \n",
    "                                                    demand_name\n",
    "                                                    ]].copy()\n",
    "\n",
    "    print(f\"{supply_name} and {demand_name} data has been merged successfully\")\n",
    "    return final_us_house_supply_demand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wake_house_market(wake_supply_df, wake_demand_df, fillna_date_list):\n",
    "    \"\"\"Pre processing Wake housing market dataframe\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    wake_supply_df : pandas dataframe\n",
    "        Wake housing market supply dataframe\n",
    "    wake_demand_df : pandas dataframe\n",
    "        Wake housing market demand dataframe\n",
    "    fillna_date_list : list\n",
    "        List of dates to fillna\n",
    "    \"\"\"\n",
    "    wake_supply_df.rename(columns={'DATE':'date', 'SUSCCOUNTY37183':wake_supply_name}, inplace=True)\n",
    "    wake_supply_df['date'] = pd.to_datetime(wake_supply_df['date'])\n",
    "    wake_supply_df['date'] = wake_supply_df['date'].dt.strftime(date_format_ym)\n",
    "    wake_supply_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    wake_demand_df.rename(columns={'DATE':'date', 'DESCCOUNTY37183':wake_demand_name}, inplace=True)\n",
    "    wake_demand_df['date'] = pd.to_datetime(wake_demand_df['date'])\n",
    "    wake_demand_df['date'] = wake_demand_df['date'].dt.strftime(date_format_ym)\n",
    "    wake_demand_df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    wake_house_supply_demand_df = wake_supply_df.merge(wake_demand_df, \n",
    "                                                       left_on='date', \n",
    "                                                       right_on='date', \n",
    "                                                       how='left')\n",
    "    wake_supply_dict = {}\n",
    "    wake_demand_dict = {}\n",
    "\n",
    "    count_i = 1\n",
    "    for date in fillna_date_list:\n",
    "        wake_supply_dict[date] = 0\n",
    "        wake_demand_dict[date] = 0\n",
    "        wake_supply_dict[date] = wake_house_supply_demand_df.iloc[:count_i].mean()[0]\n",
    "        wake_demand_dict[date] = wake_house_supply_demand_df.iloc[:count_i].mean()[1]\n",
    "        count_i += 1\n",
    "\n",
    "    new_wake_supply_df = pd.DataFrame.from_dict(wake_supply_dict, orient='index', columns=[wake_supply_name])\n",
    "    new_wake_supply_df.reset_index(inplace=True)\n",
    "    new_wake_demand_df = pd.DataFrame.from_dict(wake_demand_dict, orient='index', columns=[wake_demand_name])\n",
    "    new_wake_demand_df.reset_index(inplace=True)\n",
    "\n",
    "    new_wake_demand_df = new_wake_supply_df.merge(new_wake_demand_df, \n",
    "                                                  left_on='index', \n",
    "                                                  right_on='index', \n",
    "                                                  how='left')\n",
    "    # new_wake_demand_df.rename(columns={'wake_supply_index_x':'wake_supply_index', 'wake_supply_index_y': 'wake_supply_index'}, inplace=True)\n",
    "    new_wake_demand_df.rename(columns={'index':'date'}, inplace=True)\n",
    "    supply_demand_dict = {}\n",
    "    for date in date_list:\n",
    "        supply_demand_dict['date'] = 0\n",
    "        supply_demand_dict[wake_supply_name] = 0\n",
    "        supply_demand_dict[wake_demand_name] = 0\n",
    "        supply_demand_dict['date'] = date\n",
    "        supply_demand_dict[wake_supply_name] = new_wake_demand_df.loc[\n",
    "                                                        new_wake_demand_df['date'] == date, \n",
    "                                                        wake_supply_name\n",
    "                                                        ].values[0]\n",
    "        supply_demand_dict[wake_demand_name] = new_wake_demand_df.loc[\n",
    "                                                        new_wake_demand_df['date'] == date, \n",
    "                                                        wake_demand_name\n",
    "                                                        ].values[0]\n",
    "        wake_house_supply_demand_df = wake_house_supply_demand_df.append(supply_demand_dict, \n",
    "                                                                        ignore_index=True)\n",
    "\n",
    "    wake_house_supply_demand_df.sort_values(by='date', inplace=True)\n",
    "    wake_house_supply_demand_df.reset_index(drop=True, inplace=True)\n",
    "    print(f\"{wake_supply_name} and {wake_demand_name} data has been merged successfully\")\n",
    "    return wake_house_supply_demand_df\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_house_market(us_house_market_df, wake_house_market_df, updated_house_df):\n",
    "    \"\"\"Final housing market dataframe\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    us_house_market_df : pandas dataframe\n",
    "        US housing market dataframe\n",
    "    wake_house_market_df : pandas dataframe\n",
    "        Wake housing market dataframe\n",
    "    updated_house_df : pandas dataframe\n",
    "        Updated housing market dataframe\n",
    "    \"\"\"\n",
    "    updated_house_df['year'] = updated_house_df['deed_date'].dt.strftime(date_format_ym)\n",
    "    updated_house_df['year'] = pd.to_datetime(updated_house_df['year'])\n",
    "    us_house_market_df['date'] = pd.to_datetime(us_house_market_df['date'])\n",
    "    wake_house_market_df['date'] = pd.to_datetime(wake_house_market_df['date'])\n",
    "    updated_house_df = updated_house_df.merge(\n",
    "                                              us_house_market_df, \n",
    "                                              left_on='year', \n",
    "                                              right_on='date', \n",
    "                                              how='left'\n",
    "                                              )\n",
    "    updated_house_df = updated_house_df.merge(\n",
    "                                              wake_house_market_df, \n",
    "                                              left_on='year', \n",
    "                                              right_on='date', \n",
    "                                              how='left'\n",
    "                                              )\n",
    "    updated_house_df.drop(columns=['year', 'date_x', 'date_y'], inplace=True)\n",
    "\n",
    "    print(updated_house_df.shape)\n",
    "    print(f\"Final house market data and Updated house data has been merged successfully\")\n",
    "    return updated_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wake_crime(\n",
    "    crime_df, city_name, added_year=None, add_start=None, add_end=None, \n",
    "    multi_num=None, multi_year=None, multi_start=None, multi_end=None,  \n",
    "    if_added=False, if_added_multi=False):\n",
    "    \"\"\"Pre processing Wake crime dataframe\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    crime_df : pandas dataframe\n",
    "        Wake crime dataframe\n",
    "    city_name : str\n",
    "        City name\n",
    "    added_year : int\n",
    "        Year to add\n",
    "    add_start : str\n",
    "        Start date to add\n",
    "    add_end : str\n",
    "        End date to add\n",
    "    multi_num : int\n",
    "        Number to multiply\n",
    "    multi_year : int\n",
    "        Year to multiply\n",
    "    multi_start : str\n",
    "        Start date to multiply\n",
    "    multi_end : str\n",
    "        End date to multiply\n",
    "    if_added : bool (default: False)\n",
    "        If need to add missing values\n",
    "    if_added_multi : bool (default: False)\n",
    "        If need to add multiple missing values\n",
    "    \"\"\"\n",
    "    crime_df = crime_df.transpose()\n",
    "    crime_df.reset_index(inplace=True)\n",
    "\n",
    "    crime_df.drop(labels=[0], axis=0, inplace=True)\n",
    "    crime_df.rename(columns={'index':'year', 0:city_name}, inplace=True)\n",
    "    crime_df.drop(labels=[1], axis=1, inplace=True)\n",
    "\n",
    "    if if_added:\n",
    "        if if_added_multi:\n",
    "            for i in range(multi_num):\n",
    "                crime_df = crime_df.append({\n",
    "                                        'year': multi_year[i], \n",
    "                                        city_name:crime_df.iloc[multi_start[i]:multi_end[i], 1].median()\n",
    "                                        }, ignore_index=True)\n",
    "        else: \n",
    "            crime_df = crime_df.append({\n",
    "                                        'year': added_year, \n",
    "                                        city_name:crime_df.iloc[add_start:add_end, 1].median()\n",
    "                                        }, ignore_index=True)\n",
    "    crime_df['year'] = crime_df['year'].astype(int)\n",
    "    crime_df[city_name] = crime_df[city_name].astype(int)\n",
    "    crime_df = crime_df.sort_values(by='year')\n",
    "    crime_df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "    print(f\"{city_name} crime data has been merged successfully\")\n",
    "    return crime_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_crime(\n",
    "    updated_house_df, apex_crime, cary_crime, fuquay_varina_crime, \n",
    "    garner_crime, holly_springs_crime, knightdale_crime, morrisville_crime, \n",
    "    raleigh_crime, rolesville_crime, wake_forest_crime, wendell_crime, \n",
    "    zenbulon_crime, merge_on='year'):\n",
    "    \"\"\"Combine all crime dataframes to updated house dataframe\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    updated_house_df : pandas dataframe\n",
    "        Updated house dataframe\n",
    "    apex_crime : pandas dataframe\n",
    "        Apex crime dataframe\n",
    "    cary_crime : pandas dataframe\n",
    "        Cary crime dataframe\n",
    "    fuquay_varina_crime : pandas dataframe\n",
    "        Fuquay Varina crime dataframe\n",
    "    garner_crime : pandas dataframe\n",
    "        Garner crime dataframe\n",
    "    holly_springs_crime : pandas dataframe\n",
    "        Holly Springs crime dataframe\n",
    "    knightdale_crime : pandas dataframe\n",
    "        Knightdale crime dataframe\n",
    "    morrisville_crime : pandas dataframe\n",
    "        Morrisville crime dataframe\n",
    "    raleigh_crime : pandas dataframe\n",
    "        Raleigh crime dataframe\n",
    "    rolesville_crime : pandas dataframe\n",
    "        Rolesville crime dataframe\n",
    "    wake_forest_crime : pandas dataframe\n",
    "        Wake Forest crime dataframe\n",
    "    wendell_crime : pandas dataframe\n",
    "        Wendell crime dataframe\n",
    "    zenbulon_crime : pandas dataframe\n",
    "        Zenbulon crime dataframe\n",
    "    merge_on : str (default: 'year')\n",
    "        Column to merge on\n",
    "    \"\"\"\n",
    "    \n",
    "    updated_house_df[merge_on] = updated_house_df['deed_date'].dt.strftime(date_format_y)\n",
    "    updated_house_df[merge_on] = updated_house_df[merge_on].astype(int)\n",
    "    updated_house_df['crime'] = 0\n",
    "\n",
    "    for i in range(len(apex_crime)):\n",
    "        updated_house_df.loc[\n",
    "                            (updated_house_df['physical_city'] == 'apex') & (updated_house_df[merge_on] == apex_crime.iloc[i, 0]), \n",
    "                            'crime'\n",
    "                            ] = apex_crime.iloc[i, 1]\n",
    "        updated_house_df.loc[\n",
    "                            (updated_house_df['physical_city'] == 'cary') & (updated_house_df[merge_on] == cary_crime.iloc[i, 0]), \n",
    "                            'crime'\n",
    "                            ] = cary_crime.iloc[i, 1]\n",
    "        updated_house_df.loc[\n",
    "                            (updated_house_df['physical_city'] == 'fuquay_varina') & (updated_house_df[merge_on] == fuquay_varina_crime.iloc[i, 0]), \n",
    "                            'crime'\n",
    "                            ] = fuquay_varina_crime.iloc[i, 1]\n",
    "        updated_house_df.loc[\n",
    "                            (updated_house_df['physical_city'] == 'garner') & (updated_house_df[merge_on] == garner_crime.iloc[i, 0]), \n",
    "                            'crime'\n",
    "                            ] = garner_crime.iloc[i, 1]\n",
    "        updated_house_df.loc[\n",
    "                            (updated_house_df['physical_city'] == 'knightdale') & (updated_house_df[merge_on] == knightdale_crime.iloc[i, 0]), \n",
    "                            'crime'\n",
    "                            ] = knightdale_crime.iloc[i, 1]\n",
    "        updated_house_df.loc[\n",
    "                            (updated_house_df['physical_city'] == 'morrisville') & (updated_house_df[merge_on] == morrisville_crime.iloc[i, 0]), \n",
    "                            'crime'\n",
    "                            ] = morrisville_crime.iloc[i, 1]\n",
    "        updated_house_df.loc[\n",
    "                            (updated_house_df['physical_city'] == 'hollyspring') & (updated_house_df[merge_on] == holly_springs_crime.iloc[i, 0]), \n",
    "                            'crime'\n",
    "                            ] = holly_springs_crime.iloc[i, 1]\n",
    "        updated_house_df.loc[\n",
    "                            (updated_house_df['physical_city'] == 'raleigh') & (updated_house_df[merge_on] == raleigh_crime.iloc[i, 0]), \n",
    "                            'crime'\n",
    "                            ] = raleigh_crime.iloc[i, 1]\n",
    "        updated_house_df.loc[\n",
    "                            (updated_house_df['physical_city'] == 'rolesville') & (updated_house_df[merge_on] == rolesville_crime.iloc[i, 0]), \n",
    "                            'crime'\n",
    "                            ] = rolesville_crime.iloc[i, 1]\n",
    "        updated_house_df.loc[\n",
    "                            (updated_house_df['physical_city'] == 'wake_forest') & (updated_house_df[merge_on] == wake_forest_crime.iloc[i, 0]), \n",
    "                            'crime'\n",
    "                            ] = wake_forest_crime.iloc[i, 1]\n",
    "        updated_house_df.loc[\n",
    "                            (updated_house_df['physical_city'] == 'wendell') & (updated_house_df[merge_on] == wendell_crime.iloc[i, 0]), \n",
    "                            'crime'\n",
    "                            ] = wendell_crime.iloc[i, 1]\n",
    "        updated_house_df.loc[\n",
    "                            (updated_house_df['physical_city'] == 'zebulon') & (updated_house_df[merge_on] == zenbulon_crime.iloc[i, 0]), \n",
    "                            'crime'\n",
    "                            ] = zenbulon_crime.iloc[i, 1]\n",
    "\n",
    "    print(updated_house_df.shape)\n",
    "    return updated_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def utility_data(updated_house_df):\n",
    "    \"\"\"Add utility data to updated house dataframe\n",
    "    \n",
    "    Args:\n",
    "    ----------\n",
    "    updated_house_df : pandas dataframe\n",
    "        Updated house dataframe\n",
    "    \"\"\"\n",
    "    updated_house_df['electric'] = 0\n",
    "    updated_house_df['gas'] = 0\n",
    "    updated_house_df['water'] = 0\n",
    "    updated_house_df['sewer'] = 0\n",
    "    updated_house_df['all'] = 0\n",
    "\n",
    "    # ALL, E, GE, G, W, S, WE, SE, WSE, SGE, WS, WSG, WG, SG, WGE\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"ALL\", 'electric'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"ALL\", 'gas'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"ALL\", 'water'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"ALL\", 'sewer'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"ALL\", 'all'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"E\", 'electric'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"GE\", 'electric'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"GE\", 'gas'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"G\", 'gas'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"W\", 'water'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"S\", 'sewer'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WE\", 'electric'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WE\", 'water'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"SE\", 'electric'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"SE\", 'sewer'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WSE\", 'electric'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WSE\", 'water'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WSE\", 'sewer'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"SGE\", 'electric'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"SGE\", 'gas'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"SGE\", 'sewer'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WS\", 'water'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WS\", 'sewer'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WSG\", 'gas'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WSG\", 'water'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WSG\", 'sewer'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WG\", 'gas'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WG\", 'water'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"SG\", 'gas'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"SG\", 'sewer'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WGE\", 'sewer'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WGE\", 'water'] = 1\n",
    "    updated_house_df.loc[updated_house_df['utilities'] == \"WGE\", 'gas'] = 1\n",
    "\n",
    "    # remove the utilities column\n",
    "    updated_house_df.drop(columns=['utilities'], inplace=True)\n",
    "    print(updated_house_df.shape)\n",
    "    print(\"Utilities are converted successfully!\")\n",
    "    print(\"Utilities are added successfully!\")\n",
    "    return updated_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def final_df(updated_house_df, removed_column):\n",
    "    \"\"\"Final process house dataframe, such as removing unnecessary columns\"\"\"\n",
    "    updated_house_df.drop(columns=removed_column, inplace=True)\n",
    "    print(f\"{removed_column} column has been removed\")\n",
    "    print(updated_house_df.shape)\n",
    "    return updated_house_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_data(df, ml_type, removed_col=None, keeped_col=None, minmax_scaled_col=None):\n",
    "    if ml_type == \"unsupervised\":\n",
    "        df['assessed_value_per_heated_area'] = df['assessed_building_value'] / df['heated_area']\n",
    "        df['covid_year_timeline'] = df['year']-2020\n",
    "        df['physical_zip_code'] = df['physical_zip_code'].astype('str')\n",
    "\n",
    "        # # if cols are not from removed_col, keeped_col, and minmax_scaled_col, we take that categorical (non number) cols for OneHotEncoding\n",
    "        # df_pro_1 = df.drop(columns=removed_col + keeped_col + minmax_scaled_col)\n",
    "        # col_onehot_cat = df_pro_1.select_dtypes(exclude=np.number).columns.tolist()\n",
    "        # # if cols are not from removed_col, keeped_col, and minmax_scaled_col, they are the remaining numeric cols, we now check for skewness\n",
    "        # df_pro_2 = df.drop(columns=col_onehot_cat).columns.tolist()\n",
    "        # skew_check = df[df_pro_2].skew()\n",
    "\n",
    "        # col_log_scale = skew_check.loc[skew_check >= 1].index.tolist()\n",
    "        # col_scale = skew_check.loc[skew_check < 1].index.tolist()\n",
    "        # print('log scaled', col_log_scale)\n",
    "        # print('std scales', col_scale)\n",
    "    else:\n",
    "        print(\"Cannot process the data for supervised learning\") \n",
    "        pass\n",
    "\n",
    "    return df#, df_pro_1, df_pro_2, col_onehot_cat, col_log_scale, col_scale\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data ['house_path'] is loaded successfully!\n",
      "The data ['pop_growth_path_1'] is loaded successfully!\n",
      "The data ['pop_growth_path_2'] is loaded successfully!\n",
      "The data ['pop_growth_path_3'] is loaded successfully!\n",
      "The data ['unemploy_path'] is loaded successfully!\n",
      "The data ['covid_path'] is loaded successfully!\n",
      "The data ['mort_rate_path'] is loaded successfully!\n",
      "The data ['lumber_path'] is loaded successfully!\n",
      "The data ['metals_path'] is loaded successfully!\n",
      "The data ['build_material_path'] is loaded successfully!\n",
      "The data ['int_rate_path'] is loaded successfully!\n",
      "The data ['us_house_supply_path'],             Manufactured_Annual sheet is loaded successfully!\n",
      "The data ['us_house_demand_path'],             HAI_Annual sheet is loaded successfully!\n",
      "The data ['wake_supply_path'] is loaded successfully!\n",
      "The data ['wake_demand_path'] is loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "house_df = read_file(csv, house_path, folder_path)\n",
    "pop_growth_df_1 = read_file(csv, pop_growth_path_1, folder_path, encoding=encoding_format)\n",
    "pop_growth_df_2 = read_file(csv, pop_growth_path_2, folder_path, encoding=encoding_format)\n",
    "pop_growth_df_3 = read_file(csv, pop_growth_path_3, folder_path, encoding=encoding_format)\n",
    "unemploy_df = read_file(csv, unemploy_path, folder_path)\n",
    "covid_df = read_file(csv, covid_path, folder_path)\n",
    "mort_rate_df = read_file(csv, mort_rate_path, folder_path)\n",
    "lumber_df = read_file(csv, lumber_path, folder_path)\n",
    "metals_df = read_file(csv, metals_path, folder_path)\n",
    "build_material_df = read_file(csv, build_material_path, folder_path)\n",
    "int_rate_df = read_file(csv, int_rate_path, folder_path)\n",
    "us_house_supply_df = read_file(xlsx, us_house_supply_path, folder_path, encoding=encoding_format, sheet_name='Manufactured_Annual')\n",
    "us_house_demand_df = read_file(xlsx, us_house_demand_path, folder_path, encoding=encoding_format, sheet_name='HAI_Annual')\n",
    "wake_supply_df = read_file(csv, wake_supply_path, folder_path)\n",
    "wake_demand_df = read_file(csv, wake_demand_path, folder_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(278913, 18)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Land_Sale_Price', 'Total_sale_Price', 'Deed_Date',\n",
       "       'Assessed_Building_Value', 'Story_Height', 'HEATED_AREA', 'UTILITIES',\n",
       "       'BATH', 'BATH_FIXTURES', 'TYPE_AND_USE', 'PHYSICAL_ZIP_CODE',\n",
       "       'PHYSICAL_CITY', 'Street_Number', 'Street_Name', 'Street_Type',\n",
       "       'Planning_Jurisdiction', 'address'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "house_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The data ['crime_apex_path'] is loaded successfully!\n",
      "The data ['crime_cary_path'] is loaded successfully!\n",
      "The data ['crime_fuquay_varina_path'] is loaded successfully!\n",
      "The data ['crime_holly_springs_path'] is loaded successfully!\n",
      "The data ['crime_garner_path'] is loaded successfully!\n",
      "The data ['crime_morrisville_path'] is loaded successfully!\n",
      "The data ['crime_knightdale_path'] is loaded successfully!\n",
      "The data ['crime_raleigh_path'] is loaded successfully!\n",
      "The data ['crime_rolesville_path'] is loaded successfully!\n",
      "The data ['crime_wake_forest_path'] is loaded successfully!\n",
      "The data ['crime_wendell_path'] is loaded successfully!\n",
      "The data ['crime_zenbulon_path'] is loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "apex = read_file(csv, crime_apex_path, folder_path, sub_folder_path)\n",
    "cary = read_file(csv, crime_cary_path, folder_path, sub_folder_path)\n",
    "fuquay_varina = read_file(csv, crime_fuquay_varina_path, folder_path, sub_folder_path)\n",
    "holly_springs = read_file(csv, crime_holly_springs_path, folder_path, sub_folder_path)\n",
    "garner = read_file(csv, crime_garner_path, folder_path, sub_folder_path)\n",
    "morrisville = read_file(csv, crime_morrisville_path, folder_path, sub_folder_path)\n",
    "knightdale = read_file(csv, crime_knightdale_path, folder_path, sub_folder_path)\n",
    "raleigh = read_file(csv, crime_raleigh_path, folder_path, sub_folder_path)\n",
    "rolesville = read_file(csv, crime_rolesville_path, folder_path, sub_folder_path)\n",
    "wake_forest = read_file(csv, crime_wake_forest_path, folder_path, sub_folder_path)\n",
    "wendell = read_file(csv, crime_wendell_path, folder_path, sub_folder_path)\n",
    "zenbulon = read_file(csv, crime_zenbulon_path, folder_path, sub_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mortgage rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new mortgage rate data              mort_rate_2022 is added successfully!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliso\\AppData\\Local\\Temp/ipykernel_23800/79843710.py:13: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  mort_rate_df = mort_rate_df.append(added_mort_rate, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278913, 18)\n",
      "The mortgage rate data is merged successfully!\n"
     ]
    }
   ],
   "source": [
    "updated_house_df = mortgage_rate_df(house_df, mort_rate_df, mort_rate_2022)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unemployment rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(278913, 19)\n",
      "The unemployment rate data is merged successfully!\n"
     ]
    }
   ],
   "source": [
    "updated_house_df = unemployment_rate_df(unemploy_df, updated_house_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Population growth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population growth data 2000-2010 has been processed successfully\n",
      "Population growth data 2011-2020 has been processed successfully\n",
      "Population growth data 2021-2022 has been processed successfully\n"
     ]
    }
   ],
   "source": [
    "pop_growth_df_1 = pre_population_growth_df(\n",
    "                                    pop_growth_df_1, updated_house_df, \n",
    "                                    state_name, county_name, \"2000-2010\")\n",
    "pop_growth_df_2 = pre_population_growth_df(\n",
    "                                    pop_growth_df_2, updated_house_df, \n",
    "                                    state_name, county_name, \"2011-2020\")\n",
    "pop_growth_df_3 = pre_population_growth_df(\n",
    "                                    pop_growth_df_3, updated_house_df, \n",
    "                                    state_name, county_name, \"2021-2022\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combine all population growth datasets together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we missed 2000 and 2022 population data, we will use 2010 and 2020 Census Total Population annual growth rate respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aliso\\AppData\\Local\\Temp/ipykernel_23800/4089894297.py:28: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  final_pop_growth = final_pop_growth.append(added_pop_growth, ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Population growth data has been merged successfully\n",
      "(278913, 20)\n"
     ]
    }
   ],
   "source": [
    "updated_house_df = final_pop_growth_df(pop_growth_df_1, pop_growth_df_2, pop_growth_df_3, updated_house_df, added_pop_growth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## COVID data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pre_covid_df = pre_covid_df(covid_df, updated_house_df, state_short_name, county_name, start_date, covid_date, end_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_df = final_covid_df(updated_house_df, pre_covid_df, covid_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Raw materials data\n",
    "### Lumber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we missed 2000 to 2003 values for build_price, we will use the average of 2004 to fill up these zero values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lumber_df = raw_material_df(material_lumber, lumber_df, material_date)\n",
    "metal_df = raw_material_df(material_metal, metals_df, material_date)\n",
    "build_df = raw_material_df(material_build, build_material_df, material_date)\n",
    "build_df = fill_build_price(build_df)\n",
    "\n",
    "updated_house_df = final_material_df(\n",
    "                                    lumber_df, metal_df, \n",
    "                                    build_df, updated_house_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interest rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_df = interest_rate_df(\n",
    "                                int_rate_df, updated_house_df, \n",
    "                                country_name, int_rate_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment the below to save the dataframes to csv files\n",
    "# us_int_rate_final.to_csv('assets/us_int_rate.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## House demand and supply data\n",
    "### US House demand and supply"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### US house supply data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "us_house_supply = us_house_market(us_house_supply_df, us_house_supply_name, us_house_date)\n",
    "us_house_demand = us_house_market(us_house_demand_df, us_house_demand_name, us_house_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_us_house_market = final_us_house_market(\n",
    "                                us_house_supply, us_house_demand, us_house_supply_name, \n",
    "                                us_house_demand_name, us_house_start_date, us_house_end_date)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wake Market Hotness\n",
    "Wake market hotness only contains data after 2017\n",
    "#### Wake supply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wake_house_supply_demand_df = wake_house_market(wake_supply_df, wake_demand_df, date_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_df = final_house_market(final_us_house_market, wake_house_supply_demand_df, updated_house_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Crime data in Wake, NC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "apex_crime = wake_crime(\n",
    "                    apex, apex_city, apex_added_year, \n",
    "                    apex_start, apex_end, if_added=True)\n",
    "cary_crime = wake_crime(cary, cary_city)\n",
    "fuquay_varina_crime = wake_crime(fuquay_varina, fuquay_varina_city)\n",
    "garner_crime = wake_crime(garner, garner_city)\n",
    "holly_springs_crime = wake_crime(\n",
    "                            holly_springs, holly_springs_city, hollysprings_added_year, \n",
    "                            hollysprings_start, hollysprings_end, if_added=True)\n",
    "knightdale_crime = wake_crime(\n",
    "                            knightdale, knightdale_city, multi_num=2, multi_year=knightdale_added_year, \n",
    "                            multi_start=knightdale_start, multi_end=knightdale_end, \n",
    "                            if_added=True, if_added_multi=True)\n",
    "morrisville_crime = wake_crime(morrisville, morrisville_city)\n",
    "raleigh_crime = wake_crime(\n",
    "                        raleigh, raleigh_city, multi_num=3, multi_year=raleigh_added_year, \n",
    "                        multi_start=raleigh_start, multi_end=raleigh_end, \n",
    "                        if_added=True, if_added_multi=True)\n",
    "rolesville_crime = wake_crime(\n",
    "                        rolesville, rolesville_city, rolesville_added_year, \n",
    "                        rolesville_start, rolesville_end, if_added=True)\n",
    "wake_forest_crime = wake_crime(\n",
    "                        wake_forest, wake_forest_city, wake_forest_added_year, \n",
    "                        wake_forest_start, wake_forest_end, if_added=True)\n",
    "wendell_crime = wake_crime(wendell, wendell_city)\n",
    "zenbulon_crime = wake_crime(\n",
    "                        zenbulon, zenbulon_city, zenbulon_added_year, \n",
    "                        zenbulon_start, zenbulon_end, if_added=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_df = final_crime(\n",
    "                        updated_house_df, apex_crime, cary_crime, fuquay_varina_crime, \n",
    "                        garner_crime, holly_springs_crime, knightdale_crime, morrisville_crime, \n",
    "                        raleigh_crime, rolesville_crime, wake_forest_crime, wendell_crime, \n",
    "                        zenbulon_crime, merge_on='year')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine crime data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's read code description file and we will find the following:\n",
    "* E: electric\n",
    "* G: gas\n",
    "* W: water\n",
    "* S: sewer\n",
    "\n",
    "Let's make utilities variable as several sub-utility boolean (1 or 0) variables, like below\n",
    "* electric\n",
    "* gas\n",
    "* water\n",
    "* sewer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_df = utility_data(updated_house_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove unneccassary columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_df = final_df(updated_house_df, removed_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data\n",
    "\n",
    "Unsupervised Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_df = preprocessing_data(updated_house_df, ml_type=\"unsupervised\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "updated_house_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "msno.bar(updated_house_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since there is no Wake County house supply and demand data before 2017, we will leave the missing values as it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save as a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# uncomment to save the data as a CSV file in your local drive if needed\n",
    "updated_house_df.to_csv(os.path.join(folder_path, 'updated_house_df.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "72572667d892e1791183c326e3aa8bbc0ee980c8a9bf058479e648f1904c68bf"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
